{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGsoD5S1-3gz"
      },
      "source": [
        "# Simple Linear Regression Project\n",
        "\n",
        "\n",
        "## Modelling the linear relationship between Sales and Advertising dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vjkr/Simple-Linear-Regression-Project.git"
      ],
      "metadata": {
        "id": "n8Bi7bSd_d3x",
        "outputId": "7f4e3c96-ffea-4f1e-e8e5-ff831b313731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Simple-Linear-Regression-Project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asx5b4xL-3g3"
      },
      "source": [
        "## Project overview\n",
        "\n",
        "\n",
        "In this project, I build a Simple Linear Regression model to study the linear relationship between Sales and Advertising dataset for a dietary weight control product.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a9PVgHs-3g4"
      },
      "source": [
        "###  Linear Regression\n",
        "\n",
        "\n",
        "Linear Regression is a statistical technique which is used to find the linear relationship between dependent and one or more independent variables. This technique is applicable for Supervised learning Regression problems where we try to predict a continuous variable.\n",
        "\n",
        "\n",
        "Linear Regression can be further classified into two types – Simple and Multiple Linear Regression. In this project, I employ Simple Linear Regression technique where I have one independent and one dependent variable. It is the simplest form of Linear Regression where we fit a straight line to the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEpYNDx--3hC"
      },
      "source": [
        "###  Simple Linear Regression (SLR)\n",
        "\n",
        "Simple Linear Regression (or SLR) is the simplest model in machine learning. It models the linear relationship between the independent and dependent variables. \n",
        "\n",
        "In this project, there is one independent or input variable which represents the Sales data and is denoted by X. Similarly, there is one dependent or output variable which represents the Advertising data and is denoted by y. We want to build a linear relationship between these variables. This linear relationship can be modelled by mathematical equation of the form:-\n",
        "\t\t\t\t \n",
        "                 \n",
        "                 Y = β0   + β1*X    -------------   (1)\n",
        "                 \n",
        "\n",
        "In this equation, X and Y are called independent and dependent variables respectively,\n",
        "\n",
        "β1 is the coefficient for independent variable and\n",
        "\n",
        "β0 is the constant term.\n",
        "\n",
        "β0 and β1 are called parameters of the model.\n",
        " \n",
        "\n",
        "\n",
        "For simplicity, we can compare the above equation with the basic line equation of the form:-\n",
        " \n",
        "                   y = ax + b       ----------------- (2)\n",
        "\n",
        "We can see that \n",
        "\n",
        "slope of the line is given by, a =  β1,  and\n",
        "\n",
        "intercept of the line by b =  β0. \n",
        "\n",
        "\n",
        "In this Simple Linear Regression model, we want to fit a line which estimates the linear relationship between X and Y. So, the question of fitting reduces to estimating the parameters of the model β0 and β1. \n",
        "\n",
        " \n",
        "\n",
        "## Ordinary Least Square Method\n",
        "\n",
        "As I have described earlier, the Sales and Advertising data are given by X and y respectively. We can draw a scatter plot between X and y which shows the relationship between them.\n",
        "\n",
        " \n",
        "\n",
        "Now, our task is to find a line which best fits this scatter plot. This line will help us to predict the value of any Target variable for any given Feature variable. This line is called **Regression line**. \n",
        "\n",
        "\n",
        "We can define an error function for any line. Then, the regression line is the one which minimizes the error function. Such an error function is also called a **Cost function**. \n",
        "\n",
        "\n",
        "## Cost Function\n",
        "\n",
        "We want the Regression line to resemble the dataset as closely as possible. In other words, we want the line to be as close to actual data points as possible. It can be achieved by minimizing the vertical distance between the actual data point and fitted line. I calculate the vertical distance between each data point and the line. This distance is called the **residual**. \n",
        "\n",
        "\n",
        "So, in a regression model, we try to minimize the residuals by finding the line of best fit. The residuals are represented by the vertical dotted lines from actual data points to the line.\n",
        "\n",
        " \n",
        "We can try to minimize the sum of the residuals, but then a large positive residual would cancel out a large negative residual. For this reason, we minimize the sum of the squares of the residuals. \n",
        "\n",
        "\n",
        "Mathematically, we denote actual data points by yi and predicted data points by ŷi. So, the residual for a data point i would be given as \n",
        "\t\t\t\t\n",
        "                di = yi -  ŷi\n",
        "\n",
        "Sum of the squares of the residuals is given as:\n",
        "\n",
        "\t\t\t\tD = Ʃ di**2       for all data points\n",
        "                \n",
        "\n",
        "This is the **Cost function**. It denotes the total error present in the model which is the sum of the total errors of each individual data point. \n",
        "\n",
        "We can estimate the parameters of the model β0 and β1 by minimize the error in the model by minimizing D. Thus, we can find the regression line given by equation (1).\n",
        "\n",
        "\n",
        "This method of finding the parameters of the model and thus regression line is called **Ordinary Least Square Method**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUmGpVzF-3hD"
      },
      "source": [
        "## The problem statement\n",
        "\n",
        "The aim of building a machine learning model is to solve a problem and to define a metric to measure model performance. \n",
        "\n",
        "The problem is to model and investigate the linear relationship between Sales and Advertising dataset for a dietary weight control product. \n",
        "\n",
        "I have used two performance metrics RMSE (Root Mean Square Value) and R2 Score value to compute our model performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Awkafzj-3hD"
      },
      "source": [
        "## Software information\n",
        "\n",
        "I did this project using Jupyter notebook (Jupyter notebook server 5.5.0).\n",
        "\n",
        "The server is running on Python (Python 3.6.5), Anaconda distribution.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFZnFrFf-3hE"
      },
      "source": [
        "## Python libraries\n",
        "\n",
        "I have Anaconda Python distribution installed on my system. It comes with most of the standard Python libraries I need for this project. The basic Python libraries used in this project are:-\n",
        "\n",
        " •\tNumpy – It provides a fast numerical array structure and operating functions.\n",
        " \n",
        " •\tpandas – It provides tools for data storage, manipulation and analysis tasks.\n",
        " \n",
        " •\tScikit-Learn – The required machine learning library in Python.\n",
        " \n",
        " •\tMatplotlib – It is the basic plotting library in Python. It provides tools for making plots. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NDnuWR73-3hE"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruh43EYz-3hG"
      },
      "source": [
        "## About the dataset\n",
        "\n",
        "The data set has been imported from the econometrics website with the following url:-\n",
        "\n",
        "http://www.econometrics.com/intro/sales.htm\n",
        "\n",
        "This data set contains Sales and Advertising expenditures for a dietary weight control product. It contains monthly data for 36 months. The variables in this data set are Sales and Advertising.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XAMOF-wP-3hG",
        "outputId": "0c680159-2bf4-4f12-f243-77be3fa735ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-404b1b423c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/Simple-Linear-Regression-Project/SALES_2_.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/SALES_2_.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/SALES_2_.csv'"
          ]
        }
      ],
      "source": [
        "# Import the data\n",
        "\n",
        "url = \"/content/Simple-Linear-Regression-Project/SALES_2_.csv\"\n",
        "df = pd.read_csv( \"/content/Simple-Linear-Regression-Project/SALES_2_.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAneqjFE-3hG"
      },
      "source": [
        "## Exploratory data analysis\n",
        "\n",
        "\n",
        "First, I import the dataset into the dataframe with the standard read_csv () function of pandas library and assign it to the df variable. Then, I conducted exploratory data analysis to get a feel for the data.\n",
        "\n",
        "\n",
        "### pandas shape attribute\n",
        "\n",
        "The shape attribute of the pandas dataframe gives the dimensions of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "zOqC2g9JBqji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYmiiF9x-3hG"
      },
      "outputs": [],
      "source": [
        "# Exploratory data analysis\n",
        "\n",
        "# View the dimensions of df\n",
        "\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXLQ0sR7-3hH"
      },
      "source": [
        "### pandas head() method\n",
        "\n",
        "I viewed the top 5 rows of the pandas dataframe with the pandas head() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsPDWHZf-3hH"
      },
      "outputs": [],
      "source": [
        "# View the top 5 rows of df\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCUcjnjH-3hI"
      },
      "source": [
        "### pandas columns attribute\n",
        "\n",
        "I renamed the column labels of the dataframe with the columns attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m6F9cwz-3hI"
      },
      "outputs": [],
      "source": [
        "# Rename columns of df dataframe\n",
        "\n",
        "df.columns = ['Sales','Advertising']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42eUJO7e-3hI"
      },
      "source": [
        "### column names renamed\n",
        "\n",
        "I viewed the renamed column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd-GmMGp-3hI"
      },
      "outputs": [],
      "source": [
        "# View the top 5 rows of df with column names renamed\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ6EyKPZ-3hJ"
      },
      "source": [
        "### pandas info() method\n",
        "\n",
        "I viewed the summary of the dataframe with the pandas info() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS00PllS-3hJ"
      },
      "outputs": [],
      "source": [
        "# View dataframe summary\n",
        "\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL7yPB7_-3hJ"
      },
      "source": [
        "### pandas describe() method\n",
        "\n",
        "I look at the descriptive statistics of the dataframe with the pandas describe() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SplsDdWf-3hK"
      },
      "outputs": [],
      "source": [
        "# View descriptive statistics\n",
        "\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVE2v1o7-3hK"
      },
      "source": [
        "## Independent and Dependent Variables\n",
        "\n",
        "\n",
        "In this project, I refer Independent variable as Feature variable and Dependent variable as Target variable. These variables are also recognized by different names as follows: -\n",
        "\n",
        "\n",
        "### Independent variable\n",
        "\n",
        "Independent variable is also called Input variable and is denoted by X. In practical applications, independent variable is also called Feature variable or Predictor variable. We can denote it as:-\n",
        "\n",
        "Independent or Input variable (X) = Feature variable = Predictor variable \n",
        "\n",
        "\n",
        "### Dependent variable\n",
        "\n",
        "Dependent variable is also called Output variable and is denoted by y. \n",
        "\n",
        "Dependent variable is also called Target variable or Response variable. It can be denoted it as follows:-\n",
        "\n",
        "Dependent or Output variable (y) = Target variable = Response variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIQ-wZ_1-3hK"
      },
      "outputs": [],
      "source": [
        "# Declare feature variable and target variable\n",
        "\n",
        "X = df['Sales'].values\n",
        "y = df['Advertising'].values\n",
        "\n",
        "# Sales and Advertising data values are given by X and y respectively.\n",
        "\n",
        "# Values attribute of pandas dataframe returns the numpy arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwO5EVCP-3hK"
      },
      "source": [
        "## Visual exploratory data analysis\n",
        "\n",
        "I visualize the relationship between X and y by plotting a scatterplot between X and y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx_k5t21-3hL"
      },
      "outputs": [],
      "source": [
        "# Plot scatter plot between X and y\n",
        "\n",
        "plt.scatter(X, y, color = 'blue', label='Scatter Plot')\n",
        "plt.title('Relationship between Sales and Advertising')\n",
        "plt.xlabel('Sales')\n",
        "plt.ylabel('Advertising')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0YtFwcI-3hL"
      },
      "source": [
        "## Checking dimensions of X and y\n",
        "\n",
        "We need to check the dimensions of X and y to make sure they are in right format for Scikit-Learn API. \n",
        "\n",
        "It is an important precursor to model building. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMrorPNz-3hL"
      },
      "outputs": [],
      "source": [
        "# Print the dimensions of X and y\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N57xk7Y_-3hL"
      },
      "source": [
        "## Reshaping X and y\n",
        "\n",
        "Since we are working with only one feature variable, so we need to reshape using Numpy reshape() method.\n",
        "\n",
        "It specifies first dimension to be -1, which means \"unspecified\".\n",
        "\n",
        "Its value is inferred from the length of the array and the remaining dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhhvwoMv-3hL"
      },
      "outputs": [],
      "source": [
        "# Reshape X and y\n",
        "\n",
        "X = X.reshape(-1,1)\n",
        "y = y.reshape(-1,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXt72DVL-3hM"
      },
      "outputs": [],
      "source": [
        "# Print the dimensions of X and y after reshaping\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQynklzJ-3hM"
      },
      "source": [
        "## Difference in dimensions of X and y after reshaping\n",
        "\n",
        "\n",
        "We can see the difference in diminsions of X and y before and after reshaping.\n",
        "\n",
        "It is essential in this case because getting the feature and target variable right is an important precursor to model building."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MagIzI9q-3hM"
      },
      "source": [
        "\n",
        "## Train test split\n",
        "\n",
        "\n",
        "I split the dataset into two sets namely - train set and test set.\n",
        "\n",
        "The model learn the relationships from the training data and predict on test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn2y76ss-3hM"
      },
      "outputs": [],
      "source": [
        "# Split X and y into training and test data sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDc-7mfM-3hM"
      },
      "outputs": [],
      "source": [
        "# Print the dimensions of X_train,X_test,y_train,y_test\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56YkkN9Q-3hN"
      },
      "source": [
        "## Mechanics of the model\n",
        "\n",
        "\n",
        "I split the dataset into two sets – the training set and the test set. Then, I instantiate the regressor lm and fit it on the training set with the fit method. \n",
        "\n",
        "In this step, the model learned the relationships between the training data (X_train, y_train). \n",
        "\n",
        "Now the model is ready to make predictions on the test data (X_test). Hence, I predict on the test data using the predict method. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPG_YV8L-3hN"
      },
      "outputs": [],
      "source": [
        "# Fit the linear model\n",
        "\n",
        "# Instantiate the linear regression object lm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lm = LinearRegression()\n",
        "\n",
        "\n",
        "# Train the model using training data sets\n",
        "lm.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred=lm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_test)"
      ],
      "metadata": {
        "id": "LXwjZi8TGUo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEF6FHS--3hN"
      },
      "source": [
        "## Model slope and intercept term\n",
        "\n",
        "The model slope is given by lm.coef_ and model intercept term is given by lm.intercept_. \n",
        "\n",
        "The estimated model slope and intercept values are 1.60509347 and  -11.16003616.\n",
        "\n",
        "So, the equation of the fitted regression line is\n",
        "\n",
        "y = 1.60509347 * x - 11.16003616  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u-phLZa-3hO"
      },
      "outputs": [],
      "source": [
        "# Compute model slope and intercept\n",
        "\n",
        "a = lm.coef_\n",
        "b = lm.intercept_,\n",
        "print(\"Estimated model slope, a:\" , a)\n",
        "print(\"Estimated model intercept, b:\" , b) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9djQC58-3hO"
      },
      "source": [
        "## Making predictions\n",
        "\n",
        "\n",
        "I have predicted the Advertising values on first five 5 Sales datasets by writing code\n",
        "\n",
        "\n",
        "\t\tlm.predict(X) [0:5]  \n",
        "        \n",
        "\n",
        "If I remove [0:5], then I will get predicted Advertising values for the whole Sales dataset.\n",
        "\n",
        "\n",
        "To make prediction, on an individual Sales value, I write\n",
        "\n",
        "\n",
        "\t\tlm.predict(Xi)\n",
        "        \n",
        "\n",
        "where Xi is the Sales data value of the ith observation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OIu08vR-3hO"
      },
      "outputs": [],
      "source": [
        "# Predicting Advertising values\n",
        "\n",
        "lm.predict(X)[0:5]\n",
        "\n",
        "# Predicting Advertising values on first five Sales values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPWwxOzu-3hP"
      },
      "source": [
        "## Regression metrics for model performance\n",
        "\n",
        "\n",
        "Now, it is the time to evaluate model performance. \n",
        "\n",
        "For regression problems, there are two ways to compute the model performance. They are RMSE (Root Mean Square Error) and R-Squared Value. These are explained below:-  \n",
        "\n",
        "\n",
        "### RMSE\n",
        "\n",
        "RMSE is the standard deviation of the residuals. So, RMSE gives us the standard deviation of the unexplained variance by the model. It can be calculated by taking square root of Mean Squared Error.\n",
        "RMSE is an absolute measure of fit. It gives us how spread the residuals are, given by the standard deviation of the residuals. The more concentrated the data is around the regression line, the lower the residuals and hence lower the standard deviation of residuals. It results in lower values of RMSE. So, lower values of RMSE indicate better fit of data. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OcZOX-V-3hP"
      },
      "outputs": [],
      "source": [
        "# Calculate and print Root Mean Square Error(RMSE)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"RMSE value: {:.4f}\".format(rmse))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QkTCvRl-3hP"
      },
      "source": [
        "###  R2 Score\n",
        "\n",
        "\n",
        "R2 Score is another metric to evaluate performance of a regression model. It is also called coefficient of determination. It gives us an idea of goodness of fit for the linear regression models. It indicates the percentage of variance that is explained by the model. \n",
        "\n",
        "\n",
        "Mathematically, \n",
        "\n",
        "\n",
        "R2 Score = Explained Variation/Total Variation\n",
        "\n",
        "\n",
        "In general, the higher the R2 Score value, the better the model fits the data. Usually, its value ranges from 0 to 1. So, we want its value to be as close to 1. Its value can become negative if our model is wrong.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d22Dgdf4-3hP"
      },
      "outputs": [],
      "source": [
        "# Calculate and print r2_score\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "print (\"R2 Score value: {:.4f}\".format(r2_score(y_test, y_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jrUdflS-3hQ"
      },
      "source": [
        "## Interpretation and Conclusion\n",
        "\n",
        "\n",
        "The RMSE value has been found to be 11.2273. It means the standard deviation for our prediction is 11.2273. So, sometimes we expect the predictions to be off by more than 11.2273 and other times we expect less than 11.2273. So, the model is not good fit to the data. \n",
        "\n",
        "\n",
        "In business decisions, the benchmark for the R2 score value is 0.7. It means if R2 score value >= 0.7, then the model is good enough to deploy on unseen data whereas if R2 score value < 0.7, then the model is not good enough to deploy. Our R2 score value has been found to be .5789. It means that this model explains 57.89 % of the variance in our dependent variable. So, the R2 score value confirms that the model is not good enough to deploy because it does not provide good fit to the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1PQ1rQH-3hQ"
      },
      "outputs": [],
      "source": [
        "# Plot the Regression Line\n",
        "\n",
        "\n",
        "plt.scatter(X, y, color = 'blue', label='Scatter Plot')\n",
        "plt.plot(X_test, y_pred, color = 'black', linewidth=3, label = 'Regression Line')\n",
        "plt.title('Relationship between Sales and Advertising')\n",
        "plt.xlabel('Sales')\n",
        "plt.ylabel('Advertising')\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvD57tOg-3hQ"
      },
      "source": [
        "## Residual analysis\n",
        "\n",
        "\n",
        "\n",
        "A linear regression model may not represent the data appropriately. The model may be a poor fit to the data. So, we should validate our model by defining and examining residual plots.\n",
        "\n",
        "The difference between the observed value of the dependent variable (y) and the predicted value (ŷi) is called the residual and is denoted by e. The scatter-plot of these residuals is called residual plot.\n",
        "\n",
        "If the data points in a residual plot are randomly dispersed around horizontal axis and an approximate zero residual mean, a linear regression model may be appropriate for the data. Otherwise a non-linear model may be more appropriate.\n",
        "\n",
        "If we take a look at the generated ‘Residual errors’ plot, we can clearly see that the train data plot pattern is non-random. Same is the case with the test data plot pattern.\n",
        "So, it suggests a better-fit for a non-linear model. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKON78lY-3hQ"
      },
      "outputs": [],
      "source": [
        "# Plotting residual errors\n",
        "\n",
        "plt.scatter(lm.predict(X_train), lm.predict(X_train) - y_train, color = 'red', label = 'Train data')\n",
        "plt.scatter(lm.predict(X_test), lm.predict(X_test) - y_test, color = 'blue', label = 'Test data')\n",
        "plt.hlines(xmin = 0, xmax = 50, y = 0, linewidth = 3)\n",
        "plt.title('Residual errors')\n",
        "plt.legend(loc = 4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0rhamg_-3hR"
      },
      "source": [
        "## Checking for Overfitting and Underfitting\n",
        "\n",
        "\n",
        "I calculate training set score as 0.2861. Similarly, I calculate test set score as 0.5789. \n",
        "The training set score is very poor. So, the model does not learn the relationships appropriately from the training data. Thus, the model performs poorly on the training data. It is a clear sign of Underfitting. Hence, I validated my finding that the linear regression model does not provide good fit to the data. \n",
        "\n",
        "\n",
        "Underfitting means our model performs poorly on the training data. It means the model does not capture the relationships between the training data. This problem can be improved by increasing model complexity. We should use more powerful models like Polynomial regression to increase model complexity. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-9kX-RY-3hR"
      },
      "outputs": [],
      "source": [
        "# Checking for Overfitting or Underfitting the data\n",
        "\n",
        "print(\"Training set score: {:.4f}\".format(lm.score(X_train,y_train)))\n",
        "\n",
        "print(\"Test set score: {:.4f}\".format(lm.score(X_test,y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiIIxxN2-3hR"
      },
      "source": [
        "## Simple Linear Regression - Model Assumptions\n",
        "\n",
        "\n",
        "\n",
        "The Linear Regression Model is based on several assumptions which are listed below:-\n",
        "\n",
        "i.\tLinear relationship\n",
        "ii.\tMultivariate normality\n",
        "iii.\tNo or little multicollinearity\n",
        "iv.\tNo auto-correlation\n",
        "v.\tHomoscedasticity\n",
        "\n",
        "\n",
        "### i.\tLinear relationship\n",
        "\n",
        "\n",
        "The relationship between response and feature variables should be linear. This linear relationship assumption can be tested by plotting a scatter-plot between response and feature variables.\n",
        "\n",
        "\n",
        "### ii.\tMultivariate normality\n",
        "\n",
        "The linear regression model requires all variables to be multivariate normal. A multivariate normal distribution means a vector in multiple normally distributed variables, where any linear combination of the variables is also normally distributed.\n",
        "\n",
        "\n",
        "### iii.\tNo or little multicollinearity\n",
        "\n",
        "It is assumed that there is little or no multicollinearity in the data. Multicollinearity occurs when the features (or independent variables) are highly correlated.\n",
        "\n",
        "\n",
        "### iv.\tNo auto-correlation\n",
        "\n",
        "Also, it is assumed that there is little or no auto-correlation in the data. Autocorrelation occurs when the residual errors are not independent from each other.\n",
        "\n",
        "\n",
        "### v.\tHomoscedasticity\n",
        "\n",
        "Homoscedasticity describes a situation in which the error term (that is, the noise in the model) is the same across all values of the independent variables. It means the residuals are same across the regression line. It can be checked by looking at scatter plot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkYxblaG-3hR"
      },
      "source": [
        "## References\n",
        "\n",
        "\n",
        "The concepts and ideas in this project have been taken from the following websites and books:-\n",
        "\n",
        "i.\tMachine learning notes by Andrew Ng\n",
        "\n",
        "ii.\thttps://en.wikipedia.org/wiki/Linear_regression\n",
        "\n",
        "iii.https://en.wikipedia.org/wiki/Simple_linear_regression\n",
        "\n",
        "iv.\thttps://en.wikipedia.org/wiki/Ordinary_least_squares\n",
        "\n",
        "v.\thttps://en.wikipedia.org/wiki/Root-mean-square_deviation\n",
        "\n",
        "vi.\thttps://en.wikipedia.org/wiki/Coefficient_of_determination\n",
        "\n",
        "vii.https://www.statisticssolutions.com/assumptions-of-linear-regression/\n",
        "\n",
        "viii.Python Data Science Handbook by Jake VanderPlas\n",
        "\n",
        "ix.\tHands-On Machine Learning with Scikit Learn and Tensorflow by Aurilien Geron\n",
        "\n",
        "x.\tIntroduction to Machine Learning with Python by Andreas C Muller and Sarah Guido\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}